#коллаборативные системы
#просто решает большинство задач
# кластеризует пользователей по предпочтениям и на выходе готовая рекомендация
#
import numpy as np
import pandas as pd
ratings_df = pd.read_csv("./ratings.csv")
print()
print()
print()
#срез n= 100 в нашем случае а не 85к
#масштабируем выборку и сортируем 1->n
#берем муви ид описываем скале муви ид, нумеруем фильмы и применяем функцию на df
# sklearn нужна для разделения ds на тестовый и тренировочный
#разбиение 75 (тренировояный, осмысление смысла и заставления работать) на 25 (тестовый для валидации)%
#ля рценки качества оценки нужно исп. алгоритм rmse (square error)
# np.nan_to_num =- пустое в число преобр.
# предиктион
# граунд реальные оценки пользователей только для соотв наблра данных
# np.zeros() создает матрицу четотам на чето там
# i й польз, j й фильм
# ищем похожих пользователей которые также оценивали фильмы
# косинусное расстояние , берем расстояне между эдементами вектора (векторизованную матрицу) с неким набором признаков, идем по ней
# и  можем посмотреть на наивные рекомендации -> ищем предсказанную оценку
# берем i-й фильм и n пользоват оценивших фильм , оценка фильма - среднее значение
# movie_df = pd.read... берем дф совмещаем  itembased и связку польз и фмльма  merge()  .drop()-dsrblsdftv cnjk,tw
# берем средний рейтинг и группируем по назв и рейтингу и находим среднее и сортируем (groupby('title')....
# изем абсолютный рейтинг, смотрим абсолютные числа (сумма всех оценок пользователей)
# группируем по назв и рейт и считаем колво оценок сортируем *код далее числа типа 290 298 и тд по убыванию ascending - сортировка
# насколько точная оценка? берем фильмы смотрим оценку среднюю и сколько оценило челов (фильм 5* рейт с оценкой 1 пользователя должен быть ниже)
# строим гистограмму с разбиениями, такой то фильм стокато ползователей (прим. почти 6к одним польз, около тыщи двумя и тд)
# самая банальная система рекомендация: берем таблицу, делаем сортировку, применяем pivor_tab получаем новую таблицу,
# береем польз рейтинг звездных войн и другого фильмы и выбираем билжайшие к ним фильмы (corrwith())
# далее видим средний рейт и колво оценок + сортировка moviemat[]
# чето выводим получаем таблицу с корреляци, ближайщее к тем фильмам, чем больше корреляц тем лучше тут у нас реки на основе категорий (хз)
# далее для фильма лжец лжец лжец корреляции с указанием колва оценок >100
# далее бзе теории, реализация норм системы
# устанавливаем пакеты (scikit-surprise)
# выкачиваем ds, делаем эннзип, считываем рейтинг убираем timestamp, чето считываем переводим в дс
# конфигурация ноутбука configure (мне не надо)
# конфы отображ графика
# описание плотли go.bar. какая ось, че по иску, индексы данных, такая то легенда, позиция текста блабла (красота)
# ИДЕТ распределение рейтинга по количеству фильма с такимито рейтингами, шаг деления 0.5 (некратных 0.5 нет тут или же они округляются)
# нам нужен анализ, сколько у нас  (0-1 оценка у 10 тыс фильмов, сколько то у 12к и тд
# применяем алгоритм svd - берем матрицу и приводим к какноничному виду, обучим алгоритм, разбиваем 75 на 25, svd привдеение матрицы к понятной форме для алгоритма
# ифыув уыешьфеув проверяепм на ошибку, смотрим что у матрицы 25 факторов, 15 эпох обучили, looserate 0.001, legualrole 0.08
# далее get_Iu фильмы оцененные пользователем и get_Ui колво польз оценивших фильм
# получаем предикшн, прогоняем через польз. оценки и высяитываем среднюю ошибку, получаем след результат
# выстраиваем гистограмму, по горизонтали рейтинг, вертикаль колво
# делаем функуию, берем пресижн , применем функцию аппроксимации и получаем опять чето
# такой то фильм с такимто пресижн, f1 описательная метрица (наскок четкий результат)
# пресижн рекол функция, прогоняем среди всех пользователей, выстраиваем некоторую зависимость оценок от рекомендаций ,
# дообучаем алгоритм (тюнинг), описываем функцию получаения предсказаний
# берем фильм 67, просим дать рекомендацию и получаем recommende _movie_ids акие вот фильмы вам понрав и выводим их в таблице
#далее нейросети
